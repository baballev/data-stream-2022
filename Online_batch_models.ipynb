{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23aa2383",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "import json\n",
    "from kafka import KafkaConsumer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#river useful packages \n",
    "from river.linear_model import LinearRegression\n",
    "from river import optim\n",
    "from river.optim import Adam\n",
    "from river.neural_net import MLPRegressor, activations\n",
    "from river import metrics\n",
    "from river.optim import losses\n",
    "from river import preprocessing, evaluate, neighbors, tree\n",
    "\n",
    "# We will use the linear regression, MLP and adaptative random forest \n",
    "linear = (preprocessing.StandardScaler() |\n",
    "              LinearRegression(optimizer=optim.SGD(1e-4)))\n",
    "\n",
    "MLP = (\n",
    "     preprocessing.StandardScaler() |\n",
    "         MLPRegressor(\n",
    "             hidden_dims=(10,),\n",
    "             activations=(\n",
    "                 activations.ReLU(),\n",
    "                 activations.ReLU(),\n",
    "                 activations.ReLU()\n",
    "             ),\n",
    "             optimizer=optim.SGD(1e-4),\n",
    "             seed=42\n",
    "         )\n",
    "     )\n",
    "\n",
    "tr = (preprocessing.StandardScaler() |\n",
    "      tree.HoeffdingTreeRegressor(\n",
    "         grace_period=100,\n",
    "          max_depth=30,\n",
    "         leaf_prediction='adaptive',\n",
    "         model_selector_decay=0.9\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = \"depth20-btc\"\n",
    "consumer = KafkaConsumer(topic_name, bootstrap_servers=\"localhost:9092\")\n",
    "\n",
    "price_norm_factor = 45000.0\n",
    "qtity_norm_factor = 5.0\n",
    "\n",
    "metric = {'linear':metrics.MSE(), 'MLP':metrics.MSE(),\n",
    "                 \"tr\":metrics.MSE()}\n",
    "data = pd.DataFrame(columns=[str(i) for i in range(79)])  # That's the data we use to predict Y\n",
    "Y = [] # the output we retrieved\n",
    "k=0\n",
    "try:\n",
    "    for message in consumer:\n",
    "        print(message)\n",
    "        json_obj = json.loads(message.value)\n",
    "        #timestamp = json_obj[\"time\"]\n",
    "        bids = json_obj[\"bids\"]\n",
    "        asks = json_obj[\"asks\"]\n",
    "        l = [(float(ask[0]) - price_norm_factor)/price_norm_factor for ask in asks] + \\\n",
    "                [(float(ask[1])-qtity_norm_factor)/qtity_norm_factor for ask in asks] + \\\n",
    "                [(float(bid[0])-price_norm_factor)/price_norm_factor for bid in bids] + \\\n",
    "                [(float(bid[1])-qtity_norm_factor)/qtity_norm_factor for bid in bids]\n",
    "    \n",
    "        y = l.pop(0) # minnimum selligng price\n",
    "        X = {str(i):l[i] for i in range(len(l))}\n",
    "        \n",
    "        \"\"\"\n",
    "        y = tensor.pop(40) # maximum buying price\n",
    "        We can use the maximum buying price as our input in the model \n",
    "        Tensor ready to use input, normalized and we can use instead the StandardScaler inside a \n",
    "        pipeline to normalize the data.\n",
    "        \"\"\"\n",
    "    \n",
    "        #Make online prediction with streaming model\n",
    "        y_linear = linear.predict_one(X)\n",
    "        metric[\"linear\"] = metric[\"linear\"].update(y, y_linear)\n",
    "        linear = linear.learn_one(X, y)\n",
    "    \n",
    "        y_MLP = MLP.predict_one(X)\n",
    "        metric[\"MLP\"] = metric[\"MLP\"].update(y, y_MLP)\n",
    "        MLP = MLP.learn_one(X, y)\n",
    "    \n",
    "        y_tr = tr.predict_one(X)\n",
    "        metric[\"tr\"] = metric[\"tr\"].update(y, y_tr)\n",
    "        tr = tr.learn_one(X, y)\n",
    "        \"------------------------------------------\"\n",
    "        data = data.append(X, ignore_index = True)\n",
    "        Y.append(y)\n",
    "        k+=1\n",
    "        if k>2000:\n",
    "            print(f\"We have passed throught {k} examples\")\n",
    "            break\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"The user has stopped the process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be19c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final metric of the linear model is : 0.0\n",
      "The final metric of the tree model is : 0.0\n",
      "The final metric of the MLP model is : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The final metric of the linear model is :\",metric[\"linear\"].get())\n",
    "print(\"The final metric of the tree model is :\",metric[\"tr\"].get())\n",
    "print(\"The final metric of the MLP model is :\",metric[\"MLP\"].get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "709f1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we try to use the batch algorithms on the same dataset \"data\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "a1af6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sklearn = LinearRegression()\n",
    "rf_sklearn = RandomForestRegressor(n_estimators=100)\n",
    "MLP_sklearn = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "49faa4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor()"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_sklearn.fit(data, Y)\n",
    "rf_sklearn.fit(data, Y)\n",
    "MLP_sklearn.fit(data, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "174372a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final metric of the linear model is : 1.4456561996401147e-11\n",
      "The final metric of the random forest model is : 2.3921493771601245e-12\n",
      "The final metric of the MLP model is : 0.0005617775512273568\n"
     ]
    }
   ],
   "source": [
    "y_pred = linear_sklearn.predict(data)\n",
    "mse_linear = mean_squared_error(Y, y_pred)\n",
    "y_pred = rf_sklearn.predict(data)\n",
    "mse_rf = mean_squared_error(Y, y_pred)\n",
    "y_pred = MLP_sklearn.predict(data)\n",
    "mse_mlp = mean_squared_error(Y, y_pred)\n",
    "\"------------------------------------------\"\n",
    "print(\"The final metric of the linear model is :\",mse_linear)\n",
    "print(\"The final metric of the random forest model is :\",mse_rf)\n",
    "print(\"The final metric of the MLP model is :\",mse_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe48a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
